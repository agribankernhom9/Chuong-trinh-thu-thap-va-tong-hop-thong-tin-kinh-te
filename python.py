# -*- coding: utf-8 -*-
# ============================================================
# CH∆Ø∆†NG TR√åNH THU TH·∫¨P V√Ä T·ªîNG H·ª¢P TH√îNG TIN KINH T·∫æ Vƒ® M√î
# C·ª¶A VI·ªÜT NAM TR√äN TH·ªä TR∆Ø·ªúNG T√ÄI CH√çNH
# ============================================================

import os
import io
import math
import requests
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from concurrent.futures import ThreadPoolExecutor, as_completed

# (Lu√¥n b·∫≠t) OpenAI cho "AI ph√¢n t√≠ch v√† t∆∞ v·∫•n"
OPENAI_OK = False
try:
    from openai import OpenAI
    OPENAI_OK = True
except Exception:
    OPENAI_OK = False

# ---------------------------
# Tham s·ªë & T·ª´ ƒëi·ªÉn hi·ªÉn th·ªã
# ---------------------------
WB_API_BASE = "https://api.worldbank.org/v2"
UNDP_API_BASE = "https://hdr.undp.org/sites/default/files/api/"
HDI_PSEUDO_CODE = "UNDP.HDI"

# Danh m·ª•c m·∫∑c ƒë·ªãnh (code, EN name, unit)
DEFAULT_INDICATORS = [
    ("NY.GDP.MKTP.KD.ZG", "GDP growth (annual %)", "%"),
    ("FP.CPI.TOTL.ZG", "Inflation, CPI (annual %)", "%"),
    ("SL.UEM.TOTL.ZS", "Unemployment (% labor force)", "%"),
    ("NE.EXP.GNFS.ZS", "Exports of goods & services (% of GDP)", "%"),
    ("NE.IMP.GNFS.ZS", "Imports of goods & services (% of GDP)", "%"),
    ("GC.DOD.TOTL.GD.ZS", "Central government debt (% of GDP)", "%"),
    ("BX.KLT.DINV.WD.GD.ZS", "FDI, net inflows (% of GDP)", "%"),
    ("SP.POP.TOTL", "Population (total)", "persons"),
    ("NY.GDP.PCAP.CD", "GDP per capita (current US$)", "USD"),
]

# Ch·ªâ s·ªë m·ªü r·ªông (SBV/IMF/GSO) ‚Äî d√πng proxy WB khi API g·ªëc ch∆∞a s·∫µn (ghi r√µ ngu·ªìn)
# C√≥ th·ªÉ thay th·∫ø b·∫±ng API ch√≠nh th·ª©c khi b·∫°n cung c·∫•p endpoint/kh√≥a.
EXTENDED_INDICATORS = [
    ("FR.INR.LEND", "L√£i su·∫•t cho vay (%)", "%", "WB proxy (IMF/GSO)"),
    ("FR.INR.DPST", "L√£i su·∫•t ti·ªÅn g·ª≠i (%)", "%", "WB proxy (IMF/GSO)"),
    ("PA.NUS.FCRF", "T·ª∑ gi√° ch√≠nh th·ª©c (LCU/USD)", "LCU/USD", "WB proxy (SBV)"),
    # Placeholder n·∫øu mu·ªën ri√™ng l√£i su·∫•t ƒëi·ªÅu h√†nh SBV: s·∫Ω ƒë·ªÉ tr·ªëng khi ch∆∞a c√≥ API ch√≠nh th·ª©c
    ("SBV.POLICY.RATE", "L√£i su·∫•t ƒëi·ªÅu h√†nh (SBV) (%)", "%", "SBV (placeholder)"),
]

VN_NAME_MAP = {
    "NY.GDP.MKTP.KD.ZG": ("TƒÉng tr∆∞·ªüng GDP (nƒÉm)", "%"),
    "FP.CPI.TOTL.ZG": ("L·∫°m ph√°t CPI (nƒÉm)", "%"),
    "SL.UEM.TOTL.ZS": ("T·ª∑ l·ªá th·∫•t nghi·ªáp", "%"),
    "NE.EXP.GNFS.ZS": ("Xu·∫•t kh·∫©u h√†ng h√≥a & d·ªãch v·ª•", "% GDP"),
    "NE.IMP.GNFS.ZS": ("Nh·∫≠p kh·∫©u h√†ng h√≥a & d·ªãch v·ª•", "% GDP"),
    "GC.DOD.TOTL.GD.ZS": ("N·ª£ ch√≠nh ph·ªß", "% GDP"),
    "BX.KLT.DINV.WD.GD.ZS": ("FDI, d√≤ng v·ªën r√≤ng", "% GDP"),
    "SP.POP.TOTL": ("D√¢n s·ªë", "ng∆∞·ªùi"),
    "NY.GDP.PCAP.CD": ("GDP b√¨nh qu√¢n ƒë·∫ßu ng∆∞·ªùi", "USD"),
    HDI_PSEUDO_CODE: ("Ch·ªâ s·ªë ph√°t tri·ªÉn con ng∆∞·ªùi (HDI)", ""),
    # Extended:
    "FR.INR.LEND": ("L√£i su·∫•t cho vay", "%"),
    "FR.INR.DPST": ("L√£i su·∫•t ti·ªÅn g·ª≠i", "%"),
    "PA.NUS.FCRF": ("T·ª∑ gi√° ch√≠nh th·ª©c (LCU/USD)", "LCU/USD"),
    "SBV.POLICY.RATE": ("L√£i su·∫•t ƒëi·ªÅu h√†nh (SBV)", "%"),
}

AGRIBANK_RGB = "rgb(174,28,63)"   # #AE1C3F

def get_vn_label_with_unit(code: str) -> str:
    vn_name, vn_unit = VN_NAME_MAP.get(code, (None, None))
    if vn_name is None:
        en_unit, en_name = "", code
        for c, name, unit in DEFAULT_INDICATORS + [(x[0], x[1], x[2]) for x in EXTENDED_INDICATORS]:
            if c == code:
                en_name = name
                en_unit = unit
                break
        return f"{en_name} ({en_unit})" if en_unit else en_name
    return f"{vn_name} ({vn_unit})" if vn_unit else vn_name

def is_percent_unit(code: str) -> bool:
    _, unit = VN_NAME_MAP.get(code, (None, None))
    if unit is None:
        for c, _, u in DEFAULT_INDICATORS + [(x[0], x[1], x[2]) for x in EXTENDED_INDICATORS]:
            if c == code:
                unit = u
                break
    unit = (unit or "").lower()
    return "%" in unit

# ---------------------------
# T·ªëi ∆∞u: cache & song song
# ---------------------------
@st.cache_data(show_spinner=False, ttl=60*60)
def list_wb_countries():
    url = f"{WB_API_BASE}/country?format=json&per_page=400"
    resp = requests.get(url, timeout=30)
    resp.raise_for_status()
    data = resp.json()
    rows = []
    for item in data[1]:
        if item.get("region", {}).get("id") != "Aggregates":
            rows.append({"id": item["id"], "name": item["name"]})
    df = pd.DataFrame(rows).sort_values("name")
    return df

def _fetch_wb_indicator(country_code: str, indicator_code: str, start_year: int, end_year: int) -> pd.DataFrame:
    url = f"{WB_API_BASE}/country/{country_code}/indicator/{indicator_code}?date={start_year}:{end_year}&format=json&per_page=12000"
    r = requests.get(url, timeout=60)
    r.raise_for_status()
    js = r.json()
    if not isinstance(js, list) or len(js) < 2 or js[1] is None:
        return pd.DataFrame(columns=["Year", indicator_code])
    rows = []
    for rec in js[1]:
        y = rec.get("date")
        val = rec.get("value")
        try:
            y = int(y)
        except:
            continue
        rows.append({"Year": y, indicator_code: val})
    return pd.DataFrame(rows).sort_values("Year")

@st.cache_data(show_spinner=False, ttl=60*30)
def fetch_wb_indicators_parallel(country_code: str, indicator_codes: list, start_year: int, end_year: int) -> dict:
    out = {}
    with ThreadPoolExecutor(max_workers=min(8, len(indicator_codes) or 1)) as ex:
        futures = {ex.submit(_fetch_wb_indicator, country_code, code, start_year, end_year): code for code in indicator_codes}
        for fut in as_completed(futures):
            code = futures[fut]
            try:
                out[code] = fut.result()
            except Exception:
                out[code] = pd.DataFrame(columns=["Year", code])
    return out

@st.cache_data(show_spinner=False, ttl=60*30)
def fetch_undp_hdi(country_iso3: str, start_year: int, end_year: int) -> pd.DataFrame:
    try:
        url = f"{UNDP_API_BASE}v1/indicators/137506?countries={country_iso3}&years={start_year}-{end_year}"
        r = requests.get(url, timeout=40)
        r.raise_for_status()
        js = r.json()
        data = js.get("data", [])
        rows = [{"Year": int(it.get("year")), HDI_PSEUDO_CODE: it.get("value")} for it in data if it.get("year") is not None]
        return pd.DataFrame(rows).sort_values("Year")
    except Exception:
        return pd.DataFrame(columns=["Year", HDI_PSEUDO_CODE])

def fetch_extended_indicator(country_code: str, code: str, start_year: int, end_year: int) -> pd.DataFrame:
    """
    T·∫£i ch·ªâ s·ªë m·ªü r·ªông:
      - N·∫øu l√† SBV.POLICY.RATE: placeholder (tr·∫£ DF r·ªóng) khi ch∆∞a t√≠ch h·ª£p API SBV.
      - C√≤n l·∫°i: d√πng World Bank proxy.
    """
    if code == "SBV.POLICY.RATE":
        return pd.DataFrame(columns=["Year", code])
    return _fetch_wb_indicator(country_code, code, start_year, end_year)

def merge_wide(dfs: list) -> pd.DataFrame:
    out = None
    for d in dfs:
        if d is None or d.empty:
            continue
        out = d if out is None else pd.merge(out, d, on="Year", how="outer")
    return (out.sort_values("Year").reset_index(drop=True)) if out is not None else pd.DataFrame(columns=["Year"])

def impute_missing(df: pd.DataFrame, method: str):
    if df.empty:
        return df, {}
    df2 = df.copy()
    report = {}
    numeric_cols = [c for c in df2.columns if c != "Year"]
    if method == "Gi·ªØ nguy√™n (N/A)":
        pass
    elif method == "Forward/Backward fill":
        df2[numeric_cols] = df2[numeric_cols].ffill().bfill()
    elif method == "ƒêi·ªÅn trung b√¨nh theo c·ªôt":
        for c in numeric_cols:
            df2[c] = df2[c].fillna(df2[c].mean(skipna=True))
    elif method == "ƒêi·ªÅn median theo c·ªôt":
        for c in numeric_cols:
            df2[c] = df2[c].fillna(df2[c].median(skipna=True))
    for c in numeric_cols:
        report[c] = int(df2[c].isna().sum())
    return df2, report


def _format_number_vn(val, decimals_auto=True, force_decimals=None):
    """Format number theo chu·∫©n Vi·ªát Nam: . t√°ch ngh√¨n, , t√°ch th·∫≠p ph√¢n.
    - force_decimals: n·∫øu kh√¥ng None th√¨ lu√¥n d√πng s·ªë ch·ªØ s·ªë sau d·∫•u ph·∫©y n√†y
    - n·∫øu decimals_auto: |v|>=1000 -> 0; 1<=|v|<1000 -> 2; |v|<1 -> 3
    """
    import pandas as _pd
    if _pd.isna(val):
        return ""
    try:
        v = float(val)
    except Exception:
        return str(val)
    if force_decimals is not None:
        d = force_decimals
    elif decimals_auto:
        av = abs(v)
        if av >= 1000:
            d = 0
        elif av >= 1:
            d = 2
        else:
            d = 3
    else:
        d = 2
    s = f"{v:,.{d}f}"          # 1,234.56
    s = s.replace(",", "X").replace(".", ",").replace("X", ".")
    return s


def compute_descriptive_stats(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return pd.DataFrame()
    stats = []
    numeric_cols = [c for c in df.columns if c != "Year"]
    for col in numeric_cols:
        s = df[col].dropna()
        if s.empty:
            stats.append({"Ch·ªâ ti√™u": get_vn_label_with_unit(col), "Gi√° tr·ªã TB (Mean)": np.nan,
                          "ƒê·ªô l·ªách chu·∫©n (Std)": np.nan, "Nh·ªè nh·∫•t (Min)": np.nan, "NƒÉm Min": None,
                          "L·ªõn nh·∫•t (Max)": np.nan, "NƒÉm Max": None, "Trung v·ªã (Median)": np.nan,
                          "Q1": np.nan, "Q3": np.nan, "H·ªá s·ªë bi·∫øn thi√™n (CV%)": np.nan})
            continue
        mean, std = s.mean(), s.std(ddof=1)
        min_val, max_val = s.min(), s.max()
        min_year = df.loc[df[col].idxmin(), "Year"] if not s.empty else None
        max_year = df.loc[df[col].idxmax(), "Year"] if not s.empty else None
        median, q1, q3 = s.median(), s.quantile(0.25), s.quantile(0.75)
        cv = (std/mean*100.0) if mean and not math.isclose(mean, 0.0, abs_tol=1e-12) else np.nan
        stats.append({"Ch·ªâ ti√™u": get_vn_label_with_unit(col), "Gi√° tr·ªã TB (Mean)": mean, "ƒê·ªô l·ªách chu·∫©n (Std)": std,
                      "Nh·ªè nh·∫•t (Min)": min_val, "NƒÉm Min": int(min_year) if pd.notna(min_year) else None,
                      "L·ªõn nh·∫•t (Max)": max_val, "NƒÉm Max": int(max_year) if pd.notna(max_year) else None,
                      "Trung v·ªã (Median)": median, "Q1": q1, "Q3": q3, "H·ªá s·ªë bi·∫øn thi√™n (CV%)": cv})
    return pd.DataFrame(stats)

def correlation_matrix(df: pd.DataFrame) -> pd.DataFrame:
    cols = [c for c in df.columns if c != "Year"]
    return df[cols].corr(method="pearson") if len(cols) >= 2 else pd.DataFrame()

def add_trendline(df: pd.DataFrame, x: str, y: str):
    sub = df[[x, y]].dropna()
    if len(sub) < 2:
        return None
    a, b = np.polyfit(sub[x], sub[y], deg=1)
    x_line = np.linspace(sub[x].min(), sub[x].max(), 100)
    y_line = a * x_line + b
    return x_line, y_line, a, b

def to_excel_bytes(df_data: pd.DataFrame, df_stats: pd.DataFrame, corr: pd.DataFrame) -> bytes:
    import openpyxl  # ensure engine present
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df_data.to_excel(writer, index=False, sheet_name="Data")
        df_stats.to_excel(writer, index=False, sheet_name="Stats")
        (corr if not corr.empty else pd.DataFrame()).to_excel(writer, sheet_name="Correlation")
    buf.seek(0)
    return buf.read()

# ---------------------------
# Giao di·ªán (brand Agribank)
# ---------------------------
st.set_page_config(page_title="Ch∆∞∆°ng tr√¨nh thu th·∫≠p & t·ªïng h·ª£p vƒ© m√¥ VN", layout="wide")

# CSS ch·ªß ƒë·ªÅ Agribank + phong c√°ch chuy·ªÉn ƒë·ªïi s·ªë
st.markdown(f"""
<style>
:root {{ --brand: {AGRIBANK_RGB}; }}
.topbar {{
  width: 100%; padding: 8px 16px;
  background: linear-gradient(90deg, rgba(174,28,63,1) 0%, rgba(174,28,63,0.8) 60%, rgba(174,28,63,0.6) 100%);
  color: #fff; display: flex; align-items: center; gap: 12px; border-radius: 12px;
}}
.logo-chip {{ display: inline-flex; align-items:center; gap:8px; padding:6px 10px; border-radius:999px; background: rgba(255,255,255,0.15); font-weight:600; letter-spacing:0.4px; }}
.logo-dot {{ width:10px; height:10px; border-radius:50%; background:#fff; display:inline-block; }}
.main-title {{ text-align:center; color: #d80000; margin: 12px 0 2px 0; }}
.source-chips {{ display:flex; flex-wrap:wrap; gap:8px; justify-content:center; margin-bottom:6px; }}
.source-chips .chip {{ padding:4px 10px; border-radius:999px; border:1px solid rgba(174,28,63,0.3); background: rgba(174,28,63,0.06); color:#7a0f28; font-size:12px; font-weight:600; }}
.stButton>button {{ background: var(--brand); color:#fff; border:0; border-radius:10px; padding:8px 16px; font-weight:700; }}
.stButton>button:hover {{ filter: brightness(1.05); }}
.stTabs [data-baseweb="tab"] {{ font-weight:700; color:#7a0f28; }}
[data-testid="stDataFrame"] {{ border: 1px solid rgba(174,28,63,0.25); border-radius:12px; }}
[data-testid="stSidebar"] {{ background: linear-gradient(180deg, rgba(174,28,63,0.07), transparent); }}
</style>
""", unsafe_allow_html=True)

# Top bar
st.markdown("""
<div class="topbar">
  <div class="logo-chip"><span class="logo-dot"></span> AGRIBANK</div>
  <div style="font-weight:700; letter-spacing:0.3px;">Chuy·ªÉn ƒë·ªïi s·ªë ‚Ä¢ D·ªØ li·ªáu m·ªü ‚Ä¢ Ph√¢n t√≠ch th√¥ng minh</div>
</div>
""", unsafe_allow_html=True)

# Ti√™u ƒë·ªÅ ch√≠nh (in HOA, cƒÉn gi·ªØa, ƒë·ªè)
st.markdown(
    "<h1 class='main-title'>CH∆Ø∆†NG TR√åNH THU TH·∫¨P V√Ä T·ªîNG H·ª¢P TH√îNG TIN KINH T·∫æ Vƒ® M√î C·ª¶A VI·ªÜT NAM TR√äN TH·ªä TR∆Ø·ªúNG T√ÄI CH√çNH</h1>",
    unsafe_allow_html=True
)

# Chips ngu·ªìn d·ªØ li·ªáu
st.markdown("""
<div class="source-chips">
  <div class="chip">World Bank</div>
  <div class="chip">UNDP</div>
  <div class="chip">IMF</div>
  <div class="chip">GSO</div>
  <div class="chip">SBV</div>
</div>
""", unsafe_allow_html=True)

# ---------------------------
# Sidebar thi·∫øt l·∫≠p
# ---------------------------
with st.sidebar:
    st.header("Thi·∫øt l·∫≠p")

    # Qu·ªëc gia: m·∫∑c ƒë·ªãnh hi·ªÉn th·ªã "VNM - Vi·ªát Nam"
    try:
        countries_df = list_wb_countries()
        labels, id_to_label = [], {}
        for _id, _name in zip(countries_df["id"], countries_df["name"]):
            label = "VNM - Vi·ªát Nam" if _id == "VNM" else f"{_id} ‚Äî {_name}"
            labels.append(label)
            id_to_label[label] = (_id, "Vi·ªát Nam" if _id == "VNM" else _name)
        default_idx = int((countries_df["id"] == "VNM").idxmax()) if "VNM" in set(countries_df["id"]) else 0
        country_label = st.selectbox("Qu·ªëc gia", options=labels, index=default_idx)
        sel_country, sel_country_name = id_to_label[country_label][0], id_to_label[country_label][1]
    except Exception:
        st.warning("Kh√¥ng l·∫•y ƒë∆∞·ª£c danh s√°ch qu·ªëc gia t·ª´ World Bank. D√πng m·∫∑c ƒë·ªãnh: VNM - Vi·ªát Nam.")
        sel_country, sel_country_name = "VNM", "Vi·ªát Nam"

    st.subheader("Kho·∫£ng nƒÉm")
    col_y1, col_y2 = st.columns(2)
    with col_y1:
        start_year = st.number_input("T·ª´ nƒÉm", min_value=1960, max_value=2100, value=2000, step=1)
    with col_y2:
        end_year = st.number_input("ƒê·∫øn nƒÉm", min_value=1960, max_value=2100, value=2024, step=1)
    if start_year > end_year:
        st.error("Kho·∫£ng nƒÉm kh√¥ng h·ª£p l·ªá: 'T·ª´ nƒÉm' ph·∫£i ‚â§ 'ƒê·∫øn nƒÉm'.")

    st.subheader("Ch·ªâ s·ªë (World Bank)")
    indicator_map = {f"{name} [{code}]": code for code, name, _ in DEFAULT_INDICATORS}
    selection = st.multiselect(
        "Ch·ªçn ch·ªâ s·ªë",
        options=list(indicator_map.keys()),
        default=[f"{name} [{code}]" for code, name, _ in DEFAULT_INDICATORS]
    )
    selected_codes = [indicator_map[o] for o in selection]

    # Ch·ªâ s·ªë m·ªü r·ªông (SBV/IMF/GSO)
    with st.expander("Ch·ªâ s·ªë m·ªü r·ªông (SBV / IMF / GSO)"):
        ext_map = {f"{label} [{code}] ‚Äî ngu·ªìn: {src}": code for code, label, unit, src in EXTENDED_INDICATORS}
        ext_sel = st.multiselect(
            "Ch·ªçn ch·ªâ s·ªë m·ªü r·ªông",
            options=list(ext_map.keys()),
            # m·∫∑c ƒë·ªãnh ch·ªçn c√°c ch·ªâ s·ªë WB proxy, tr·ª´ placeholder SBV
            default=[f"{label} [{code}] ‚Äî ngu·ªìn: {src}" for code, label, unit, src in EXTENDED_INDICATORS if code != "SBV.POLICY.RATE"]
        )
        selected_ext = [ext_map[o] for o in ext_sel]

    if "missing_method" not in st.session_state:
        st.session_state["missing_method"] = "Gi·ªØ nguy√™n (N/A)"

# ---------------------------
# ETL: t·∫£i d·ªØ li·ªáu (song song)
# ---------------------------
with st.spinner("ƒêang l·∫•y d·ªØ li·ªáu..."):
    wb_d = fetch_wb_indicators_parallel(sel_country, selected_codes, int(start_year), int(end_year))
    ext_d = {code: fetch_extended_indicator(sel_country, code, int(start_year), int(end_year)) for code in selected_ext}

dfs = list(wb_d.values()) + list(ext_d.values())

use_hdi = False
if use_hdi:
    with st.spinner("ƒêang l·∫•y HDI t·ª´ UNDP..."):
        hdi_df = fetch_undp_hdi(sel_country, int(start_year), int(end_year))
        if not hdi_df.empty:
            dfs.append(hdi_df)

raw_df = merge_wide(dfs).copy()
has_missing = raw_df.drop(columns=["Year"]).isna().any().any() if not raw_df.empty else False

missing_method = st.session_state.get("missing_method", "Gi·ªØ nguy√™n (N/A)")
imputed_df, na_report = impute_missing(raw_df, missing_method)

stats_df = compute_descriptive_stats(imputed_df)
corr_df = correlation_matrix(imputed_df)

# ---------------------------
# Build DataFrame hi·ªÉn th·ªã & ƒë·ªãnh d·∫°ng
# ---------------------------
def build_display_df(numeric_df: pd.DataFrame) -> pd.DataFrame:
    if numeric_df.empty:
        return numeric_df
    df = numeric_df.copy()
    rename_map = {c: get_vn_label_with_unit(c) for c in df.columns if c != "Year"}
    df_renamed = df.rename(columns=rename_map)

    # ƒê·ªãnh d·∫°ng: n·∫øu KH√îNG ph·∫£i %, l√†m tr√≤n 0 & ngh√¨n ph√¢n c√°ch
    formatted = df_renamed.copy()
    inv = {get_vn_label_with_unit(code): code for code in raw_df.columns if code != "Year"}
    for c in formatted.columns:
        if c == "Year":
            continue
        code = inv.get(c, None)
        if code and not is_percent_unit(code):
            formatted[c] = formatted[c].apply(lambda v: f"{int(round(v)):,}" if pd.notna(v) else v)
        else:
            formatted[c] = formatted[c].apply(lambda v: None if pd.isna(v) else round(float(v), 2))
    return formatted

display_df = build_display_df(imputed_df)

# ---------------------------
# Tabs
# ---------------------------
tab_data, tab_charts, tab_stats, tab_download, tab_ai = st.tabs([
    "üì• D·ªØ li·ªáu",
    "üìä Bi·ªÉu ƒë·ªì",
    "üìê Th·ªëng k√™ m√¥ t·∫£",
    "‚¨áÔ∏è T·∫£i d·ªØ li·ªáu",
    "ü§ñ AI ph√¢n t√≠ch v√† t∆∞ v·∫•n"
])

with tab_data:
    st.subheader("B·∫£ng d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω")

    # X·ª≠ l√Ω thi·∫øu d·ªØ li·ªáu: ch·ªâ hi·ªán khi c√≥ thi·∫øu
    if has_missing:
        with st.expander("‚ö†Ô∏è Thi·∫øu d·ªØ li·ªáu ph√°t hi·ªán ‚Äî Ch·ªçn ph∆∞∆°ng √°n x·ª≠ l√Ω", expanded=False):
            st.selectbox(
                "Ph∆∞∆°ng √°n x·ª≠ l√Ω",
                ["Gi·ªØ nguy√™n (N/A)", "Forward/Backward fill", "ƒêi·ªÅn trung b√¨nh theo c·ªôt", "ƒêi·ªÅn median theo c·ªôt"],
                index=["Gi·ªØ nguy√™n (N/A)", "Forward/Backward fill", "ƒêi·ªÅn trung b√¨nh theo c·ªôt", "ƒêi·ªÅn median theo c·ªôt"].index(
                    st.session_state.get("missing_method", "Gi·ªØ nguy√™n (N/A)")
                ),
                key="missing_method",
                help="ƒê·ªïi l·ª±a ch·ªçn s·∫Ω t·ª± √°p d·ª•ng trong l·∫ßn t·∫£i l·∫°i."
            )
            # (1) Th√¥ng b√°o N/A: hi·ªÉn th·ªã T√äN TI·∫æNG VI·ªÜT (ƒë√∫ng nh∆∞ trong b·∫£ng)
            if any(v > 0 for v in na_report.values()):
                vn_badges = []
                for code, cnt in na_report.items():
                    if cnt > 0:
                        vn_badges.append(f"{get_vn_label_with_unit(code)}:{cnt}")
                if vn_badges:
                    st.info("Sau x·ª≠ l√Ω hi·ªán t·∫°i v·∫´n c√≤n N/A ·ªü: " + ", ".join(vn_badges))

    # C·ªôt STT b·∫Øt ƒë·∫ßu t·ª´ 1
    if not display_df.empty:
        df_show = display_df.copy()
        df_show.index = np.arange(1, len(df_show) + 1)
        df_show.index.name = "STT"
        st.dataframe(df_show, use_container_width=True, height=420)
    else:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã.")

    # Tr√≠ch ngu·ªìn
    source_list = ["World Bank Open Data"]
    if any(c in selected_ext for c in ["FR.INR.LEND", "FR.INR.DPST", "PA.NUS.FCRF"]):
        source_list.append("WB proxy cho ch·ªâ s·ªë SBV/IMF/GSO")
    if "SBV.POLICY.RATE" in selected_ext:
        source_list.append("SBV (l√£i su·∫•t ƒëi·ªÅu h√†nh ‚Äî placeholder)")
    st.caption("Ngu·ªìn d·ªØ li·ªáu: " + "; ".join(source_list))

with tab_charts:
    st.subheader("Tr·ª±c quan ho√°")
    chart_types = st.multiselect("Ch·ªçn lo·∫°i bi·ªÉu ƒë·ªì", ["Line", "Bar", "Combo", "Scatter", "Heatmap"], default=["Line", "Heatmap"])
    available_series = [c for c in imputed_df.columns if c != "Year"]
    selected_series_for_plot = st.multiselect(
        "Ch·ªçn ch·ªâ ti√™u c·∫ßn v·∫Ω",
        options=available_series,
        default=available_series,
        format_func=lambda code: get_vn_label_with_unit(code)
    )

    if imputed_df.empty or not selected_series_for_plot:
        st.info("Ch∆∞a ƒë·ªß d·ªØ li·ªáu ho·∫∑c ch∆∞a ch·ªçn ch·ªâ ti√™u.")
    else:
        df_plot = imputed_df[["Year"] + selected_series_for_plot].copy()

        if "Line" in chart_types:
            st.markdown("**Bi·ªÉu ƒë·ªì ƒë∆∞·ªùng ‚Äî Xu h∆∞·ªõng theo th·ªùi gian**")
            m = df_plot.melt(id_vars="Year", var_name="Indicator", value_name="Value")
            m["Indicator"] = m["Indicator"].apply(get_vn_label_with_unit)
            fig = px.line(m, x="Year", y="Value", color="Indicator", markers=True)
            fig.update_layout(height=450, legend_title_text="Ch·ªâ ti√™u")
            st.plotly_chart(fig, use_container_width=True)

        if "Bar" in chart_types:
            st.markdown("**Bi·ªÉu ƒë·ªì c·ªôt ‚Äî So s√°nh theo nƒÉm**")
            bar_col = st.selectbox("Ch·ªâ ti√™u cho Bar", options=selected_series_for_plot, format_func=lambda c: get_vn_label_with_unit(c))
            fig = px.bar(df_plot, x="Year", y=bar_col, title=get_vn_label_with_unit(bar_col))
            fig.update_layout(height=420, yaxis_title=get_vn_label_with_unit(bar_col))
            st.plotly_chart(fig, use_container_width=True)

        if "Combo" in chart_types:
            st.markdown("**Bi·ªÉu ƒë·ªì k·∫øt h·ª£p ‚Äî Bar + Line**")
            c1, c2 = st.columns(2)
            with c1:
                bar_c = st.selectbox("Bar =", options=selected_series_for_plot, format_func=lambda c: get_vn_label_with_unit(c), key="bar_combo")
            with c2:
                cand_line = [c for c in selected_series_for_plot if c != bar_c]
                line_c = st.selectbox("Line =", options=cand_line if cand_line else selected_series_for_plot,
                                      format_func=lambda c: get_vn_label_with_unit(c), key="line_combo")
            fig = go.Figure()
            fig.add_bar(x=df_plot["Year"], y=df_plot[bar_c], name=get_vn_label_with_unit(bar_c))
            fig.add_trace(go.Scatter(x=df_plot["Year"], y=df_plot[line_c], mode="lines+markers",
                                     name=get_vn_label_with_unit(line_c), yaxis="y2"))
            fig.update_layout(
                height=450,
                yaxis=dict(title=get_vn_label_with_unit(bar_c)),
                yaxis2=dict(title=get_vn_label_with_unit(line_c), overlaying='y', side='right'),
                legend_title_text="Ch·ªâ ti√™u"
            )
            st.plotly_chart(fig, use_container_width=True)

        if "Scatter" in chart_types:
            st.markdown("**Bi·ªÉu ƒë·ªì ph√¢n t√°n ‚Äî T∆∞∆°ng quan hai bi·∫øn**")
            colx, coly = st.columns(2)
            with colx:
                scatter_x = st.selectbox("Ch·ªçn X", options=selected_series_for_plot, format_func=lambda c: get_vn_label_with_unit(c), key="scatter_x")
            with coly:
                scatter_y = st.selectbox("Ch·ªçn Y", options=[c for c in selected_series_for_plot if c != scatter_x] or selected_series_for_plot,
                                         format_func=lambda c: get_vn_label_with_unit(c), key="scatter_y")
            sc = df_plot[[scatter_x, scatter_y, "Year"]].dropna()
            if sc.empty:
                st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ v·∫Ω Scatter.")
            else:
                fig = px.scatter(sc, x=scatter_x, y=scatter_y, hover_data=["Year"])
                fig.update_layout(xaxis_title=get_vn_label_with_unit(scatter_x), yaxis_title=get_vn_label_with_unit(scatter_y))
                fig.update_layout(height=420, xaxis_title=get_vn_label_with_unit(scatter_x), yaxis_title=get_vn_label_with_unit(scatter_y))
                trend = add_trendline(sc, scatter_x, scatter_y)
                if trend:
                    x_line, y_line, a, b = trend
                    fig.add_trace(go.Scatter(x=x_line, y=y_line, mode="lines", name=f"ƒê∆∞·ªùng xu h∆∞·ªõng (y‚âà{a:.2f}x+{b:.2f})"))
                st.plotly_chart(fig, use_container_width=True)

        if "Heatmap" in chart_types:
            st.markdown("**Bi·ªÉu ƒë·ªì nhi·ªát ‚Äî Ma tr·∫≠n t∆∞∆°ng quan**")
            corr = correlation_matrix(df_plot)
            if corr.empty:
                st.info("Ch∆∞a ƒë·ªß bi·∫øn s·ªë ƒë·ªÉ t√≠nh t∆∞∆°ng quan.")
            else:
                corr_vn = corr.copy()
                corr_vn.columns = [get_vn_label_with_unit(c) for c in corr_vn.columns]
                corr_vn.index = [get_vn_label_with_unit(c) for c in corr_vn.index]
                fig = px.imshow(corr_vn, text_auto=".2f", aspect="auto", color_continuous_scale="RdBu", origin="lower")
                fig.update_layout(height=520, coloraxis_colorbar=dict(title="r"))
                st.plotly_chart(fig, use_container_width=True)


with tab_stats:
    st.subheader("B·∫£ng th·ªëng k√™ m√¥ t·∫£")
    if stats_df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ t√≠nh th·ªëng k√™.")
    else:
        disp = stats_df.copy()

        # X√°c ƒë·ªãnh h√†ng l√† ph·∫ßn trƒÉm n·∫øu t√™n ch·ªâ ti√™u c√≥ ch·ª©a "%"
        is_percent_row = disp["Ch·ªâ ti√™u"].astype(str).str.contains("%")

        # √Åp d·ª•ng ƒë·ªãnh d·∫°ng s·ªë Vi·ªát Nam cho to√†n b·ªô c·ªôt s·ªë
        num_cols = ["Gi√° tr·ªã TB (Mean)", "ƒê·ªô l·ªách chu·∫©n (Std)", "Nh·ªè nh·∫•t (Min)",
                    "L·ªõn nh·∫•t (Max)", "Trung v·ªã (Median)", "Q1", "Q3", "H·ªá s·ªë bi·∫øn thi√™n (CV%)"]
        for c in num_cols:
            if c in disp.columns:
                def _fmt(v, is_pct):
                    # CV% v√† c√°c ch·ªâ ti√™u %: 2 ch·ªØ s·ªë sau d·∫•u ph·∫©y
                    if c == "H·ªá s·ªë bi·∫øn thi√™n (CV%)" or is_pct:
                        s = _format_number_vn(v, decimals_auto=False, force_decimals=2)
                        return (s + " %") if s != "" else s
                    # c√≤n l·∫°i ƒë·ªãnh d·∫°ng t·ª± ƒë·ªông
                    return _format_number_vn(v)
                disp[c] = [ _fmt(v, bool(is_percent_row.iloc[i]) if i < len(is_percent_row) else False)
                            for i, v in enumerate(disp[c].tolist()) ]

        disp_show = disp.copy()
        disp_show.index = np.arange(1, len(disp_show) + 1)
        disp_show.index.name = "STT"
        st.dataframe(disp_show, use_container_width=True, height=420)
        st.caption("Ngu·ªìn d·ªØ li·ªáu: " + "; ".join(source_list))
        st.caption("Ngu·ªìn d·ªØ li·ªáu: " + "; ".join(source_list))

with tab_download:
    st.subheader("T·∫£i d·ªØ li·ªáu")
    if imputed_df.empty:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ t·∫£i.")
    else:
        bytes_xlsx = to_excel_bytes(imputed_df, stats_df, corr_df if not corr_df.empty else pd.DataFrame())
        st.download_button(
            label="‚¨áÔ∏è T·∫£i Excel (Data + Stats + Correlation)",
            data=bytes_xlsx,
            file_name=f"macro_{sel_country}_{start_year}-{end_year}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        csv_bytes = imputed_df.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="‚¨áÔ∏è T·∫£i CSV (Data)",
            data=csv_bytes,
            file_name=f"macro_{sel_country}_{start_year}-{end_year}.csv",
            mime="text/csv",
            use_container_width=True
        )
        st.caption("Ngu·ªìn d·ªØ li·ªáu: " + "; ".join(source_list))

with tab_ai:
    # (2) KH√îNG hi·ªÉn th·ªã C-ADAPT; ƒë·ªÅ m·ª•c ti·∫øng Vi·ªát
    st.subheader("AI ph√¢n t√≠ch v√† t∆∞ v·∫•n")
    audience = st.selectbox("ƒê·ªëi t∆∞·ª£ng t∆∞ v·∫•n", ["Nh√† ƒë·∫ßu t∆∞", "Doanh nghi·ªáp", "Ng√¢n h√†ng (Agribank)"])

    def build_ai_prompt(audience: str, country_label: str, year_range: str,
                        stats_df: pd.DataFrame, corr_df: pd.DataFrame, selected_cols: list) -> str:
        # T√≥m t·∫Øt bi·∫øn ƒë·ªông: top CV%
        top_lines = []
        if not stats_df.empty and "H·ªá s·ªë bi·∫øn thi√™n (CV%)" in stats_df.columns:
            tmp_cv = stats_df.sort_values("H·ªá s·ªë bi·∫øn thi√™n (CV%)", ascending=False).head(3)
            for _, r in tmp_cv.iterrows():
                cvv = r["H·ªá s·ªë bi·∫øn thi√™n (CV%)"] if pd.notna(r["H·ªá s·ªë bi·∫øn thi√™n (CV%)"]) else 0
                minv = r["Nh·ªè nh·∫•t (Min)"] if pd.notna(r["Nh·ªè nh·∫•t (Min)"]) else 0
                maxv = r["L·ªõn nh·∫•t (Max)"] if pd.notna(r["L·ªõn nh·∫•t (Max)"]) else 0
                top_lines.append(f"- {r['Ch·ªâ ti√™u']}: CV‚âà{cvv:.1f}%, Min {minv:.2f} ({r['NƒÉm Min']}), Max {maxv:.2f} ({r['NƒÉm Max']}).")

        corr_lines = []
        if not corr_df.empty:
            cols = list(corr_df.columns)
            for i in range(len(cols)):
                for j in range(i+1, len(cols)):
                    r = corr_df.iloc[i, j]
                    if pd.notna(r) and abs(r) >= 0.7:
                        corr_lines.append(f"- {get_vn_label_with_unit(cols[i])} vs {get_vn_label_with_unit(cols[j])}: r={float(r):.2f}")
        if not corr_lines:
            corr_lines = ["- Ch∆∞a c√≥ t∆∞∆°ng quan m·∫°nh (|r| ‚â• 0.7)."]

        # Ch·ªâ hi·ªÉn th·ªã khuy·∫øn ngh·ªã cho ƒë√∫ng ƒë·ªëi t∆∞·ª£ng
        if audience == "Nh√† ƒë·∫ßu t∆∞":
            advice_block = """- Ph√¢n b·ªï (CK/BƒêS/v√†ng/FX) theo 2‚Äì3 k·ªãch b·∫£n (c∆° s·ªü, t√≠ch c·ª±c, th·∫≠n tr·ªçng) v·ªõi ng∆∞·ª°ng k√≠ch ho·∫°t.
- Qu·∫£n tr·ªã r·ªßi ro: stop-loss, t√°i c√¢n b·∫±ng theo bi·∫øn ƒë·ªông l·∫°m ph√°t/l√£i su·∫•t."""
        elif audience == "Doanh nghi·ªáp":
            advice_block = """- K·∫ø ho·∫°ch s·∫£n xu·∫•t/v·ªën/XNK theo k·ªãch b·∫£n c·∫ßu n·ªôi ƒë·ªãa & t·ª∑ gi√°.
- Qu·∫£n tr·ªã r·ªßi ro chi ph√≠ v·ªën (l√£i su·∫•t) v√† t·ª∑ gi√°; t·ªëi ∆∞u t·ªìn kho, chu k·ª≥ ti·ªÅn m·∫∑t."""
        else:
            advice_block = """- G√≥i cho vay ∆∞u ƒë√£i theo ng√†nh ∆∞u ti√™n; linh ho·∫°t k·ª≥ h·∫°n/l√£i su·∫•t theo k·ªãch b·∫£n.
- Ti√™u ch√≠ th·∫©m ƒë·ªãnh: DSCR, v√≤ng quay v·ªën, ƒë·ªô nh·∫°y l√£i su·∫•t/t·ª∑ gi√°; x·∫øp h·∫°ng t√≠n d·ª•ng n·ªôi b·ªô."""

        # Prompt ho√†n to√†n ti·∫øng Vi·ªát, kh√¥ng nh·∫Øc C-ADAPT
        prompt = f"""
B·∫°n l√† chuy√™n gia kinh t·∫ø & t√†i ch√≠nh. H√£y ph√¢n t√≠ch d·ªØ li·ªáu vƒ© m√¥ c·ªßa {country_label} giai ƒëo·∫°n {year_range}.
Tr√¨nh b√†y NG·∫ÆN G·ªåN theo c√°c ƒë·ªÅ m·ª•c sau (ch·ªâ d√πng ti√™u ƒë·ªÅ ti·∫øng Vi·ªát):

1) B·ªëi c·∫£nh & D·ªØ li·ªáu ch√≠nh:
- Ch·ªâ ti√™u ƒëang ph√¢n t√≠ch: {', '.join([get_vn_label_with_unit(c) for c in selected_cols])}.

2) Xu h∆∞·ªõng n·ªïi b·∫≠t & Bi·∫øn ƒë·ªông:
{os.linesep.join(top_lines) if top_lines else "- (D·ªØ li·ªáu h·∫°n ch·∫ø ƒë·ªÉ t√≥m t·∫Øt chi ti·∫øt)"} 

3) T∆∞∆°ng quan ƒë√°ng ch√∫ √Ω:
{os.linesep.join(corr_lines)}

4) Ki·∫øn ngh·ªã cho ƒë·ªëi t∆∞·ª£ng: {audience}
{advice_block}

5) H√†nh ƒë·ªông th·ª±c thi (k√®m KPI/ƒëi·ªÅu ki·ªán k√≠ch ho·∫°t):

6) R·ªßi ro ch√≠nh & C√°ch ki·ªÉm ch·ª©ng sau m·ªói k·ª≥ c√¥ng b·ªë d·ªØ li·ªáu:
"""
        return prompt.strip()

    if st.button("üöÄ Sinh AI ph√¢n t√≠ch v√† t∆∞ v·∫•n"):
        if imputed_df.empty:
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch.")
        else:
            prompt = build_ai_prompt(
                audience=audience,
                country_label=sel_country_name,
                year_range=f"{start_year}-{end_year}",
                stats_df=stats_df,
                corr_df=corr_df,
                selected_cols=[c for c in imputed_df.columns if c != "Year"]
            )
            if not OPENAI_OK:
                st.warning("‚ö†Ô∏è M√¥-ƒëun AI ch∆∞a s·∫µn s√†ng (thi·∫øu th∆∞ vi·ªán openai). H√£y c√†i ƒë·∫∑t v√† c·∫•u h√¨nh OPENAI_API_KEY.")
            else:
                api_key = os.getenv("OPENAI_API_KEY", "").strip()
                if not api_key:
                    st.warning("‚ö†Ô∏è Ch∆∞a ph√°t hi·ªán OPENAI_API_KEY. Vui l√≤ng ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng.")
                else:
                    try:
                        client = OpenAI(api_key=api_key)
                        resp = client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[
                                {"role": "system", "content": "B·∫°n l√† chuy√™n gia kinh t·∫ø vƒ© m√¥ & t√†i ch√≠nh, vi·∫øt ng·∫Øn g·ªçn, s√∫c t√≠ch, d√πng ti√™u ƒë·ªÅ ti·∫øng Vi·ªát."},
                                {"role": "user", "content": prompt},
                            ],
                            temperature=0.4,
                            max_tokens=900,
                        )
                        st.markdown(resp.choices[0].message.content)
                    except Exception as e:
                        st.error(f"L·ªói khi g·ªçi OpenAI: {e}")

# Footer
st.caption("¬© 2025 ‚Äî Viet Macro Intelligence ‚Ä¢ Ngu·ªìn: " + "; ".join(source_list))
